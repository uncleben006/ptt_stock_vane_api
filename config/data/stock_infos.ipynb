{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "stock_targets = pd.read_csv('stock_targets.csv')\n",
    "stock_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉開頭為 0 的股票代號，那些很多是 ETF，stockfeel 裡面沒有紀錄\n",
    "\n",
    "prefix_not_equal_zero = ~stock_targets['no'].str.startswith('0')\n",
    "stock_targets = stock_targets[prefix_not_equal_zero]\n",
    "stock_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取股票資訊\n",
    "\n",
    "print(\"Searching stocks info...\")\n",
    "stock_infos = []\n",
    "for index, row in stock_targets.iterrows():\n",
    "    url = 'https://www.stockfeel.com.tw/financial/?stock=' + row['no']\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for {row['no']} {row['name']}\")\n",
    "        continue\n",
    "    print(f\"Fetching data for {row['no']} {row['name']}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    business_scope_title = soup.select('div.sin-content-original')[0].select('h3')[0].text\n",
    "    business_scope_content = soup.select('div.sin-content-original')[0].select('p')[0].text\n",
    "    competitor_title = soup.select('div.sin-content-original')[0].select('h3')[2].text\n",
    "    competitor_content = soup.select('div.sin-content-original')[0].select('p')[2].text\n",
    "    competitor_table = soup.select('div.sin-content-original')[0].select('table.table-content')[0]\n",
    "    stocks = [stock.text for stock in competitor_table.find_all('td')]\n",
    "    competitor_dict = { stock_no:stock_name for stock_name, stock_no in zip(stocks[::2], stocks[1::2]) }\n",
    "    # print(business_scope_title+'？'+business_scope_content,competitor_title,competitor_content,competitor_dict)\n",
    "\n",
    "    # write into csv\n",
    "    stock_infos.append({\n",
    "        'stock_no' : row['no'],\n",
    "        'stock_name' : row['name'],\n",
    "        'business_scope':business_scope_title+'？'+business_scope_content,\n",
    "        'competitor':competitor_content+str(competitor_dict)\n",
    "    })\n",
    "\n",
    "stock_infos = pd.DataFrame(stock_infos)\n",
    "stock_infos.to_csv(\"./stock_infos.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找找看有沒有遺漏沒爬下來的的股票\n",
    "\n",
    "missing_numbers = set(stock_targets['no'].tolist()) - set(stock_infos['stock_no'].tolist())\n",
    "missing_stocks_index = stock_targets['no'].isin(missing_numbers)\n",
    "missing_stocks = stock_targets[missing_stocks_index]\n",
    "missing_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將遺漏的股票爬下來\n",
    "\n",
    "missing_stock_infos = []\n",
    "for index, row in missing_stocks.iterrows():\n",
    "    print(row['no'], row['name'])\n",
    "\n",
    "    url = 'https://www.stockfeel.com.tw/financial/?stock=' + row['no']\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for {row['no']} {row['name']}\")\n",
    "        continue\n",
    "    print(f\"Fetching data for {row['no']} {row['name']}\")\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    business_scope_title = soup.select('div.sin-content-original')[0].select('h3')[0].text\n",
    "    business_scope_content = soup.select('div.sin-content-original')[0].select('p')[0].text\n",
    "    competitor_title = soup.select('div.sin-content-original')[0].select('h3')[2].text\n",
    "    competitor_content = soup.select('div.sin-content-original')[0].select('p')[2].text\n",
    "    competitor_table = soup.select('div.sin-content-original')[0].select('table.table-content')[0]\n",
    "    stocks = [stock.text for stock in competitor_table.find_all('td')]\n",
    "    competitor_dict = { stock_no:stock_name for stock_name, stock_no in zip(stocks[::2], stocks[1::2]) }\n",
    "    # print(business_scope_title+'？'+business_scope_content,competitor_title,competitor_content,competitor_dict)\n",
    "    \n",
    "    # write into csv\n",
    "    missing_stock_infos.append({\n",
    "        'stock_no' : row['no'],\n",
    "        'stock_name' : row['name'],\n",
    "        'business_scope':business_scope_title+'？'+business_scope_content,\n",
    "        'competitor':competitor_content+str(competitor_dict)\n",
    "    })\n",
    "\n",
    "missing_stock_infos_df = pd.DataFrame(missing_stock_infos)\n",
    "missing_stock_infos_df.to_csv(\"./stock_infos2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
